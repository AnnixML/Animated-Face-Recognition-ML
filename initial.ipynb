{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 14:11:48.216451: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-25 14:11:48.216539: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-25 14:11:48.257398: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-25 14:11:48.351337: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-25 14:11:49.345819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-02-25 14:11:50.977600: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 14:11:51.130731: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 14:11:51.130825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 14:11:51.133803: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 14:11:51.133916: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 14:11:51.133990: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 14:11:51.435089: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 14:11:51.435218: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 14:11:51.435232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-25 14:11:51.435289: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 14:11:51.435309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5572 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3486\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../tags_processed_stages/dafre_tags.csv\")\n",
    "num_classes = df['tags_cat4'].nunique()\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463437"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hatsune_miku']                                                                                10644\n",
      "['hakurei_reimu']                                                                                6690\n",
      "['rumia']                                                                                        3803\n",
      "['kochiya_sanae']                                                                                3472\n",
      "['cirno']                                                                                        3470\n",
      "                                                                                                ...  \n",
      "['kirisame_marisa', 'rei_(cookie)']                                                                 1\n",
      "['cecilia_alcott', 'charlotte_dunois', 'huang_lingyin', 'orimura_ichika', 'shinonono_houki']        1\n",
      "['female_gunner_(dungeon_and_fighter)', 'rose_(elsword)']                                           1\n",
      "['oosanshouuo-san', 'ranka_lee']                                                                    1\n",
      "['night_watcher_(elsword)', 'rena_(elsword)']                                                       1\n",
      "Name: tags_cat4, Length: 3486, dtype: int64\n",
      "['hatsune_miku']                           10644\n",
      "['hakurei_reimu']                           6690\n",
      "['rumia']                                   3803\n",
      "['kochiya_sanae']                           3472\n",
      "['cirno']                                   3470\n",
      "                                           ...  \n",
      "['nekomusume']                                18\n",
      "['female_priest_(dungeon_and_fighter)']       16\n",
      "['okonogi_yuuko']                             14\n",
      "[]                                            11\n",
      "['izayoi_(blazblue)']                         10\n",
      "Name: tags_cat4, Length: 3260, dtype: int64\n",
      "3260\n",
      "3260\n",
      "3260\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['tags_cat4'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "def contains_multiple_tags(label, separator=','):\n",
    "    return separator in label\n",
    "filtered_df = df[~df['tags_cat4'].apply(contains_multiple_tags, separator=',')]\n",
    "\n",
    "class_counts = filtered_df['tags_cat4'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "train_df, temp_test_df = train_test_split(filtered_df, test_size=0.2, stratify=filtered_df['tags_cat4'])\n",
    "val_df, test_df = train_test_split(temp_test_df, test_size=0.5, stratify=temp_test_df['tags_cat4'])\n",
    "\n",
    "\n",
    "print(train_df['tags_cat4'].nunique())\n",
    "print(val_df['tags_cat4'].nunique())\n",
    "print(test_df['tags_cat4'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 369126 validated image filenames belonging to 3260 classes.\n",
      "Found 46141 validated image filenames belonging to 3260 classes.\n",
      "Found 46141 validated image filenames belonging to 3260 classes.\n",
      "(32, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../fullMin256/', \n",
    "    x_col='dir', \n",
    "    y_col='tags_cat4', \n",
    "    target_size=(224, 224), \n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode = 'rgb'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory='../fullMin256/',\n",
    "    x_col='dir',\n",
    "    y_col='tags_cat4',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    color_mode = 'rgb'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../fullMin256/',\n",
    "    x_col='dir',\n",
    "    y_col='tags_cat4',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode = 'rgb'\n",
    ")\n",
    "x,y  = next(train_generator)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFViTModel.\n",
      "\n",
      "All the weights of TFViTModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras import regularizers\n",
    "from tensorflow import keras\n",
    "#from transformers import BeitImageProcessor, BeitForImageClassification\n",
    "#from keras_cv_attention_models import beit\n",
    "from transformers import AutoImageProcessor, TFViTModel\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.4),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0, width_factor=0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2, 0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "])\n",
    "class ExtractPoolerOutput(Layer):\n",
    "    def call(self, inputs):\n",
    "        return inputs.pooler_output\n",
    "#base_model = tf.keras.applications.MobileNetV2(input_shape=(96, 96, 3), include_top=False, weights='imagenet')\n",
    "base_model = TFViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "#base_model = hub.KerasLayer(\"https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet21k-b0-classification/versions/1\")\n",
    "base_model.trainable = False\n",
    "model = Sequential()\n",
    "\n",
    "model.add(data_augmentation)\n",
    "model.add(base_model)\n",
    "model.add(ExtractPoolerOutput())\n",
    "model.add(tf.keras.layers.Dense(3260))\n",
    "#model.build((32, 224, 224, 3))\n",
    "#model.summary(show_trainable=True)\n",
    "#model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalFocalCrossentropy(), metrics=['accuracy'])\n",
    "#print(len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 14:44:59.762161: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at conv_ops_impl.h:668 : INVALID_ARGUMENT: input depth must be evenly divisible by filter depth: 224 vs 3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_36/tf_vi_t_model_17/vit/embeddings/patch_embeddings/projection/Conv2D defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_1371/2080473124.py\", line 17, in <module>\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/sequential.py\", line 413, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 767, in run_call_with_unpacked_inputs\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/models/vit/modeling_tf_vit.py\", line 769, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 767, in run_call_with_unpacked_inputs\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/models/vit/modeling_tf_vit.py\", line 599, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/models/vit/modeling_tf_vit.py\", line 129, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/models/vit/modeling_tf_vit.py\", line 204, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n\ninput depth must be evenly divisible by filter depth: 224 vs 3\n\t [[{{node sequential_36/tf_vi_t_model_17/vit/embeddings/patch_embeddings/projection/Conv2D}}]] [Op:__inference_train_function_149979]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#model.summary(show_trainable=True)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mTopKCategoricalAccuracy(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_5_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m), tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mTopKCategoricalAccuracy(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_3_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[0;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     26\u001b[0m tra_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_36/tf_vi_t_model_17/vit/embeddings/patch_embeddings/projection/Conv2D defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_1371/2080473124.py\", line 17, in <module>\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/sequential.py\", line 413, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 767, in run_call_with_unpacked_inputs\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/models/vit/modeling_tf_vit.py\", line 769, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 767, in run_call_with_unpacked_inputs\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/models/vit/modeling_tf_vit.py\", line 599, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/models/vit/modeling_tf_vit.py\", line 129, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/transformers/models/vit/modeling_tf_vit.py\", line 204, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n\n  File \"/home/leogu/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n\ninput depth must be evenly divisible by filter depth: 224 vs 3\n\t [[{{node sequential_36/tf_vi_t_model_17/vit/embeddings/patch_embeddings/projection/Conv2D}}]] [Op:__inference_train_function_149979]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "checkpoint = ModelCheckpoint(\"best_model.keras\", save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6 , mode='min', verbose=1)\n",
    "decay_steps = 1000.0\n",
    "initial_learning_rate = 0.0\n",
    "warmup_steps = 1000.0\n",
    "target_learning_rate = 0.1\n",
    "lr_warmup_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate, decay_steps, warmup_target=target_learning_rate,\n",
    "    warmup_steps=warmup_steps\n",
    ")\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.90)\n",
    "#model.summary(show_trainable=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0), metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_categorical_accuracy'), tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_categorical_accuracy')])\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=25, \n",
    "    verbose=1,\n",
    "    steps_per_epoch=2000,\n",
    "    validation_steps=len(validation_generator)/32,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr])  \n",
    "\n",
    "tra_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(tra_acc, label = \"Training Accuracy\")\n",
    "plt.plot(val_acc, label = \"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Acc\")\n",
    "\n",
    "tra_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(tra_loss, label = \"Training Loss\")\n",
    "plt.plot(val_loss, label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=100, \n",
    "    verbose=1,\n",
    "    initial_epoch = 0,\n",
    "    steps_per_epoch=500,\n",
    "    validation_steps=len(validation_generator)/32,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr])  \n",
    "\n",
    "tra_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(tra_acc, label = \"Training Accuracy\")\n",
    "plt.plot(val_acc, label = \"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Acc\")\n",
    "\n",
    "tra_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(tra_loss, label = \"Training Loss\")\n",
    "plt.plot(val_loss, label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
