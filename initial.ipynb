{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "***REMOVED***\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(\n",
    " #   physical_devices[0], True\n",
    "#)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3486\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../tags_processed_stages/dafre_tags.csv\")\n",
    "num_classes = df['tags_cat4'].nunique()\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463437"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_counts = df['tags_cat4'].value_counts()\n",
    "df_filtered = df[df['tags_cat4'].isin(class_counts[class_counts >= 2].index)]\n",
    "train_df, temp_df = train_test_split(df_filtered, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "common_classes = set(train_df['tags_cat4']).intersection(set(val_df['tags_cat4']), set(test_df['tags_cat4']))\n",
    "\n",
    "# Filter the datasets to include only common classes\n",
    "train_df = train_df[train_df['tags_cat4'].isin(common_classes)]\n",
    "val_df = val_df[val_df['tags_cat4'].isin(common_classes)]\n",
    "test_df = test_df[test_df['tags_cat4'].isin(common_classes)]\n",
    "print(val_df['tags_cat4'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Rescale the image by normalizing it.\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 366503 validated image filenames belonging to 3095 classes.\n",
      "Found 46064 validated image filenames belonging to 3095 classes.\n",
      "Found 46028 validated image filenames belonging to 3095 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../fullMin256/', # Replace with the path to the directory where images are stored\n",
    "    x_col='dir', # Column in dataframe that contains the filenames\n",
    "    y_col='tags_cat4', # Column in dataframe that has the target labels\n",
    "    target_size=(150, 150), # Size to which all images will be resized\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory='../fullMin256/',\n",
    "    x_col='dir',\n",
    "    y_col='tags_cat4',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../fullMin256/',\n",
    "    x_col='dir',\n",
    "    y_col='tags_cat4',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(3095, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 20:36:01.013816: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f7fecddf870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-30 20:36:01.013881: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Laptop GPU, Compute Capability 8.6\n",
      "2024-01-30 20:36:01.020217: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1706664961.106752  548442 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357/357 [==============================] - 95s 258ms/step - loss: 9.1157 - accuracy: 0.0319 - val_loss: 8.3840 - val_accuracy: 0.0526\n",
      "Epoch 2/20\n",
      "357/357 [==============================] - 87s 244ms/step - loss: 8.3189 - accuracy: 0.0446 - val_loss: 7.8358 - val_accuracy: 0.0658\n",
      "Epoch 3/20\n",
      "357/357 [==============================] - 81s 227ms/step - loss: 8.0004 - accuracy: 0.0546 - val_loss: 7.5561 - val_accuracy: 0.0681\n",
      "Epoch 4/20\n",
      "357/357 [==============================] - 84s 236ms/step - loss: 7.7894 - accuracy: 0.0562 - val_loss: 7.3462 - val_accuracy: 0.0735\n",
      "Epoch 5/20\n",
      "358/357 [==============================] - ETA: 0s - loss: 7.5745 - accuracy: 0.0575"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(train_generator, verbose=1, validation_data=validation_generator, validation_steps=len(validation_generator), steps_per_epoch = len(train_generator)/32, epochs = 20, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tra_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(tra_acc, label = \"Training Accuracy\")\n",
    "plt.plot(val_acc, label = \"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Acc\")\n",
    "\n",
    "tra_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(tra_loss, label = \"Training Loss\")\n",
    "plt.plot(val_loss, label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
