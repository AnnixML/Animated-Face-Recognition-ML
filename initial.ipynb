{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(\n",
    " #   physical_devices[0], True\n",
    "#)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3486\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../tags_processed_stages/dafre_tags.csv\")\n",
    "num_classes = df['tags_cat4'].nunique()\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463437"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_counts = df['tags_cat4'].value_counts()\n",
    "df_filtered = df[df['tags_cat4'].isin(class_counts[class_counts >= 2].index)]\n",
    "train_df, temp_df = train_test_split(df_filtered, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "common_classes = set(train_df['tags_cat4']).intersection(set(val_df['tags_cat4']), set(test_df['tags_cat4']))\n",
    "\n",
    "train_df = train_df[train_df['tags_cat4'].isin(common_classes)]\n",
    "val_df = val_df[val_df['tags_cat4'].isin(common_classes)]\n",
    "test_df = test_df[test_df['tags_cat4'].isin(common_classes)]\n",
    "print(val_df['tags_cat4'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 366503 validated image filenames belonging to 3095 classes.\n",
      "Found 46064 validated image filenames belonging to 3095 classes.\n",
      "Found 46028 validated image filenames belonging to 3095 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../fullMin256/', \n",
    "    x_col='dir', \n",
    "    y_col='tags_cat4', \n",
    "    target_size=(150, 150), \n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory='../fullMin256/',\n",
    "    x_col='dir',\n",
    "    y_col='tags_cat4',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../fullMin256/',\n",
    "    x_col='dir',\n",
    "    y_col='tags_cat4',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.4),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0, width_factor=0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2, 0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "])\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(150, 150, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False\n",
    "model = Sequential()\n",
    "\n",
    "model.add(data_augmentation)\n",
    "model.add(base_model)\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(3095, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalFocalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 16:54:22.425833: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-01-31 16:54:22.626685: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 16:54:23.394125: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-31 16:54:28.894422: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f7f15b59a90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-31 16:54:28.894467: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Laptop GPU, Compute Capability 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1706738068.976392   84354 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/357 [==============================] - ETA: 0s - loss: 9.8782 - accuracy: 0.0187 - top_5_categorical_accuracy: 0.0321"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leogu/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357/357 [==============================] - 51s 126ms/step - loss: 9.8782 - accuracy: 0.0187 - top_5_categorical_accuracy: 0.0321 - val_loss: 9.5194 - val_accuracy: 0.0299 - val_top_5_categorical_accuracy: 0.0674 - lr: 0.0050\n",
      "Epoch 2/100\n",
      "175/357 [=============>................] - ETA: 21s - loss: 9.4352 - accuracy: 0.0377 - top_5_categorical_accuracy: 0.0839"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, verbose=1, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5 , mode='min', verbose=1)\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9)\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_categorical_accuracy')])\n",
    "#model.build(150, 150, 3)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=100, \n",
    "    verbose=1,\n",
    "    steps_per_epoch=len(train_generator)/32,\n",
    "    validation_steps=len(validation_generator)/32,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr])  \n",
    "\n",
    "\n",
    "tra_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(tra_acc, label = \"Training Accuracy\")\n",
    "plt.plot(val_acc, label = \"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Acc\")\n",
    "\n",
    "tra_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(tra_loss, label = \"Training Loss\")\n",
    "plt.plot(val_loss, label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:75]:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_categorical_accuracy')])\n",
    "#model.summary(show_trainable=True)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=400, \n",
    "    verbose=1,\n",
    "    steps_per_epoch=len(train_generator)/32,\n",
    "    validation_steps=len(validation_generator)/32,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr])  \n",
    "\n",
    "tra_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(tra_acc, label = \"Training Accuracy\")\n",
    "plt.plot(val_acc, label = \"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Acc\")\n",
    "\n",
    "tra_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(tra_loss, label = \"Training Loss\")\n",
    "plt.plot(val_loss, label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_categorical_accuracy')])\n",
    "#model.summary(show_trainable=True)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=500, \n",
    "    verbose=1,\n",
    "    steps_per_epoch=len(train_generator)/32,\n",
    "    validation_steps=len(validation_generator)/32,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr])  \n",
    "\n",
    "tra_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(tra_acc, label = \"Training Accuracy\")\n",
    "plt.plot(val_acc, label = \"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Acc\")\n",
    "\n",
    "tra_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(tra_loss, label = \"Training Loss\")\n",
    "plt.plot(val_loss, label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
