{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 12:22:39.817973: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-29 12:22:39.818025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-29 12:22:39.818743: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-29 12:22:39.823113: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 12:22:40.501353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-02-29 12:22:41.489774: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:41.533555: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:41.533602: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:41.546854: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:41.546932: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:41.546962: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:41.807290: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:41.807428: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:41.807442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-29 12:22:41.807505: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:41.807521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5572 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3486\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../tags_processed_stages/dafre_tags.csv\")\n",
    "num_classes = df['tags_cat4'].nunique()\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hatsune_miku']                                                                                10644\n",
      "['hakurei_reimu']                                                                                6690\n",
      "['rumia']                                                                                        3803\n",
      "['kochiya_sanae']                                                                                3472\n",
      "['cirno']                                                                                        3470\n",
      "                                                                                                ...  \n",
      "['kirisame_marisa', 'rei_(cookie)']                                                                 1\n",
      "['cecilia_alcott', 'charlotte_dunois', 'huang_lingyin', 'orimura_ichika', 'shinonono_houki']        1\n",
      "['female_gunner_(dungeon_and_fighter)', 'rose_(elsword)']                                           1\n",
      "['oosanshouuo-san', 'ranka_lee']                                                                    1\n",
      "['night_watcher_(elsword)', 'rena_(elsword)']                                                       1\n",
      "Name: tags_cat4, Length: 3486, dtype: int64\n",
      "['hatsune_miku']                           10644\n",
      "['hakurei_reimu']                           6690\n",
      "['rumia']                                   3803\n",
      "['kochiya_sanae']                           3472\n",
      "['cirno']                                   3470\n",
      "                                           ...  \n",
      "['nekomusume']                                18\n",
      "['female_priest_(dungeon_and_fighter)']       16\n",
      "['okonogi_yuuko']                             14\n",
      "[]                                            11\n",
      "['izayoi_(blazblue)']                         10\n",
      "Name: tags_cat4, Length: 3260, dtype: int64\n",
      "3260\n",
      "3260\n",
      "3260\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['tags_cat4'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "def contains_multiple_tags(label, separator=','):\n",
    "    return separator in label\n",
    "filtered_df = df[~df['tags_cat4'].apply(contains_multiple_tags, separator=',')]\n",
    "\n",
    "class_counts = filtered_df['tags_cat4'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "train_df, temp_test_df = train_test_split(filtered_df, test_size=0.2, stratify=filtered_df['tags_cat4'])\n",
    "val_df, test_df = train_test_split(temp_test_df, test_size=0.5, stratify=temp_test_df['tags_cat4'])\n",
    "\n",
    "class_counts = train_df['tags_cat4'].value_counts()\n",
    "max_samples_per_class = class_counts.max()\n",
    "'''\n",
    "balanced_df = pd.concat([\n",
    "    train_df[train_df['tags_cat4'] == label].sample(max_samples_per_class, replace=True)\n",
    "    for label in df['tags_cat4'].unique()\n",
    "])\n",
    "\n",
    "balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])  # Resize if necessary\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image, label\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((balanced_df['dir'].values, balanced_df['tags_cat4'].values))\n",
    "dataset = dataset.map(preprocess_image).batch(32)\n",
    "'''\n",
    "print(train_df['tags_cat4'].nunique())\n",
    "print(val_df['tags_cat4'].nunique())\n",
    "print(test_df['tags_cat4'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 369126 validated image filenames belonging to 3260 classes.\n",
      "Found 46141 validated image filenames belonging to 3260 classes.\n",
      "Found 46141 validated image filenames belonging to 3260 classes.\n",
      "(32, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    dataframe=train_df,\n",
    "    directory='../fullMin256/', \n",
    "    x_col='dir', \n",
    "    y_col='tags_cat4', \n",
    "    target_size=(224, 224), \n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode = 'rgb'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory='../fullMin256/',\n",
    "    x_col='dir',\n",
    "    y_col='tags_cat4',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    color_mode = 'rgb'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../fullMin256/',\n",
    "    x_col='dir',\n",
    "    y_col='tags_cat4',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode = 'rgb'\n",
    ")\n",
    "x,y  = next(train_generator)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 12:22:56.743593: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:56.743726: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:56.743764: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:56.752211: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:56.752239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-29 12:22:56.752284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-29 12:22:56.752307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5572 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " sequential (Sequential)     (32, 224, 224, 3)         0         Y          \n",
      "                                                                            \n",
      " keras_layer (KerasLayer)    (32, 21841)               1099534   N          \n",
      "                                                       89                   \n",
      "                                                                            \n",
      " flatten (Flatten)           (32, 21841)               0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (32, 3260)                7120492   Y          \n",
      "                                                       0                    \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 181158409 (691.06 MB)\n",
      "Trainable params: 71204920 (271.63 MB)\n",
      "Non-trainable params: 109953489 (419.44 MB)\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling1D, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras import regularizers\n",
    "from tensorflow import keras\n",
    "#from transformers import BeitImageProcessor, BeitForImageClassification\n",
    "#from keras_cv_attention_models import beit\n",
    "from transformers import AutoImageProcessor, TFViTModel\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.4),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0, width_factor=0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2, 0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "])\n",
    "class ExtractPoolerOutput(Layer):\n",
    "    def call(self, inputs):\n",
    "        return inputs.pooler_output\n",
    "#base_model = tf.keras.applications.MobileNetV2(input_shape=(96, 96, 3), include_top=False, weights='imagenet')\n",
    "#base_model = TFViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "#image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "base_model = hub.KerasLayer(\"https://www.kaggle.com/models/spsayakpaul/convnext/frameworks/TensorFlow2/variations/base-21k-224/versions/1\", trainable=False)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(data_augmentation)\n",
    "model.add(base_model)\n",
    "#model.add(ExtractPoolerOutput())\n",
    "#model.add(GlobalAveragePooling1D())\n",
    "model.add(tf.keras.layers.Dense(3260, activation='softmax'))\n",
    "#model.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
    "model.build((32, 224, 224, 3))\n",
    "model.summary(show_trainable=True)\n",
    "#model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalFocalCrossentropy(), metrics=['accuracy'])\n",
    "#print(len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  76/2000 [>.............................] - ETA: 10:13 - loss: 8.2056 - accuracy: 0.0074 - top_5_categorical_accuracy: 0.0329 - top_3_categorical_accuracy: 0.0206"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "checkpoint = ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6 , mode='min', verbose=1)\n",
    "decay_steps = 1000.0\n",
    "initial_learning_rate = 0.0\n",
    "warmup_steps = 1000.0\n",
    "target_learning_rate = 0.1\n",
    "lr_warmup_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate, decay_steps, warmup_target=target_learning_rate,\n",
    "    warmup_steps=warmup_steps\n",
    ")\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.90)\n",
    "#model.summary(show_trainable=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1, ema_momentum=0.9), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_categorical_accuracy'), tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_categorical_accuracy')])\n",
    "model.predict_on_batch(next(test_generator))\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=50, \n",
    "    verbose=1,\n",
    "    steps_per_epoch=2000,\n",
    "    validation_steps=len(validation_generator)/32,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr])  \n",
    "\n",
    "tra_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(tra_acc, label = \"Training Accuracy\")\n",
    "plt.plot(val_acc, label = \"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Acc\")\n",
    "\n",
    "tra_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(tra_loss, label = \"Training Loss\")\n",
    "plt.plot(val_loss, label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=100, \n",
    "    verbose=1,\n",
    "    initial_epoch = 0,\n",
    "    steps_per_epoch=500,\n",
    "    validation_steps=len(validation_generator)/32,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr])  \n",
    "\n",
    "tra_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(tra_acc, label = \"Training Accuracy\")\n",
    "plt.plot(val_acc, label = \"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Acc\")\n",
    "\n",
    "tra_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(tra_loss, label = \"Training Loss\")\n",
    "plt.plot(val_loss, label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
